## Related work
{:#related_work}

### RDF Streams

In [](cite:cites arasu2006cql), a stream is defined as a (possibly infinite) bag (multiset) of elements〈s, τ〉where s is a tuple (cfr. the actual data without the timestamp of the element) belonging to the schema of S and τ ∈ T is the timestamp of the element. The Resource Description Framework (RDF) stream processing community, which focuses on processing RDF-modelled data, has applied this definition[](cite:cites dell2014rsp) for RDF streams where an RDF stream S is a (potentially) unbounded sequence of timestamped RDF statements in non-decreasing time order. While RDF allows data publishers to describe knowledge in triple-based statements, it is important to notice that a non-RDF Web stream of a live dataset only really differs from an RDF stream by its data model [](cite:cites rojas2018preliminary) and thus, we will look into how RDF streams are currently published on the Web. TripleWave[](cite:cites mauri2016triplewave) is a tool that transforms Web streams into RDF streams and republishes them with a polling and/or push-based (cfr. Websockets, MQTT) interface. These streams can be consumed by other RDF stream processors (RSP) for continuous query answering with SPARQL-based query models (C-SPARQL[](cite:cites barbieri2010c), CQLS [](cite:cites le2011native), TPF Query Streamer [](cite:cites taelman_eswc_2016)). [](cite:cites dell'aglio2017on) describes for the publication of an RDF stream that both push-based and polling interfaces can be supported; the consumer may choose what it prefers. Also, several requirements[](cite:cites dell2017stream) are defined for RSP query engines of which requirement 6 “timely fashion” acknowledges the same idea of [](cite:cites dell'aglio2017on) that the timing of results depend on the application scenario and thus, the requirements of the consumer of the data publication or query service.

### Web publication protocols

**HTTP polling** A client sends an HTTP GET request to the server to retrieve a resource. After retrieving the response, the client waits for a certain time interval and starts again with requesting the resource. The benefit of this approach is that a resource becomes stateless and HTTP caching is possible. However, there is no strict guideline on how clients should time their request. For variantly updating resources, a client can’t predict when the next update will be available. A high polling frequency could be configured to limit the latency on the client, but this comes at a higher bandwidth cost[](cite:cites lubbers2016html5).

**HTTP long polling** With long polling, the server only returns a response when a new update is available. This way, a client does not send redundant requests like HTTP polling. Also, the client doesn’t wait before sending a request again. A resource becomes stateful as the server needs to maintain all the connections open. After receiving a response, a client directly requests the resource again. [](cite:cites 6197172) showed that long polling has a similar performance as Websockets, but the underlying network latency must be lower than half the data measurement rate.

**Server-Sent Events** With the growing demand for (near) realtime applications, HTTP is extended in 2014 with the support of Server-Sent Events (SSE). Similarly to long polling, the server holds the connection open for every client, but this remains open for pushing multiple updates instead of only one. With the use of the EventSource API (supported by all browsers except IE and Edge), clients can receive updates of a resource in an event-driven fashion. Using SSE over HTTP/1.1 has the disadvantage that every requested resource requires a separate TCP connection, which can run into the limited number of connections a browser can open per domain. However, this is solved for servers that support HTTP/2, which multiplex all connections of a client over the one connection.

**Websockets** The Websockets protocol provides a bidirectional communication channel over one TCP connection for every client. It is part of the Web, because HTTP is used to set up a handshake between client and server for transmitting data, but further communication happens over a raw TCP connection. Multiple subprotocols are available to communicate over this layer. The WHATWG Websocket standard describes how messages can be pushed between client and server, but there are also other sub protocols (MQTT[](cite:cites 8088251), CoAP…) for more advanced features such as subscribing for updates of a specific resource, which is available with SSE by design. Websockets has a lower transmission latency than SSE[](cite:cites slodziak2016performance) when the server needs to send large messages above 7.5 kilobytes. Also, for client to server communication provides Websockets a lower transmission latency[](cite:cites slodziak2016performance) than using HTTP.
In the next section, we will look into how the timely fashion requirement is applied for live Open datasets.
